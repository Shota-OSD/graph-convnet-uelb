#!/usr/bin/env python3
"""
ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
"""

import torch
import json
import os
import shutil
from src.config.config_manager import ConfigManager
from src.train.trainer import Trainer

def test_model_saving_loading():
    """ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆ"""
    print("Testing model saving and loading functionality...")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®è¨­å®šã‚’ä½œæˆ
    test_config = {
        "expt_name": "test_model_persistence",
        "gpu_id": "0",
        "use_gpu": False,  # ãƒ†ã‚¹ãƒˆç”¨ã«CPUã‚’ä½¿ç”¨
        
        "num_train_data": 10,
        "num_test_data": 5,
        "num_val_data": 5,
        "num_nodes": 10,
        "num_commodities": 3,
        "sample_size": 2,
        "capacity_lower": 100,
        "capacity_higher": 1000,
        "demand_lower": 1,
        "demand_higher": 50,
        
        "node_dim": 4,
        "voc_nodes_in": 10,
        "voc_nodes_out": 2,
        "voc_edges_in": 3,
        "voc_edges_out": 2,
        
        "beam_size": 5,
        "hidden_dim": 16,
        "num_layers": 2,
        "mlp_layers": 1,
        "aggregation": "mean",
        
        "max_epochs": 2,
        "val_every": 1,
        "test_every": 1,
        
        "batch_size": 2,
        "batches_per_epoch": 2,
        "accumulation_steps": 1,
        
        "learning_rate": 0.001,
        "decay_rate": 1.0,
        "dropout_rate": 0.1,
        
        "models_dir": "./test_saved_models",
        "save_model": True,
        "save_every_epoch": True,
        "load_saved_model": False,
        "cleanup_old_models": False
    }
    
    # ãƒ†ã‚¹ãƒˆç”¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    os.makedirs("./test_configs", exist_ok=True)
    test_config_path = "./test_configs/test_model_persistence.json"
    with open(test_config_path, 'w') as f:
        json.dump(test_config, f, indent=4)
    
    try:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if os.path.exists("./test_saved_models"):
            shutil.rmtree("./test_saved_models")
        
        # Step 1: è¨­å®šã‚’èª­ã¿è¾¼ã‚“ã§ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆ
        print("\n1. Creating trainer with test config...")
        config_manager = ConfigManager(test_config_path)
        config = config_manager.get_config()
        dtypeFloat, dtypeLong = config_manager.get_dtypes()
        
        trainer1 = Trainer(config, dtypeFloat, dtypeLong)
        
        # Step 2: ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆä¿å­˜å‰ï¼‰
        print("\n2. Getting initial model parameters...")
        initial_params = {}
        for name, param in trainer1.get_model().named_parameters():
            initial_params[name] = param.data.clone()
        
        # Step 3: ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        print("\n3. Saving model...")
        trainer1.save_model(epoch=0, loss=0.5)
        
        # ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        models_dir = "./test_saved_models"
        assert os.path.exists(models_dir), f"Models directory {models_dir} not created"
        
        saved_files = os.listdir(models_dir)
        print(f"Saved files: {saved_files}")
        assert len(saved_files) > 0, "No model files were saved"
        
        # Step 4: æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆã—ã¦èª­ã¿è¾¼ã¿è¨­å®šã‚’æœ‰åŠ¹ã«ã™ã‚‹
        print("\n4. Creating new trainer with load_saved_model=True...")
        config.load_saved_model = True
        trainer2 = Trainer(config, dtypeFloat, dtypeLong)
        
        # Step 5: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
        print("\n5. Verifying loaded parameters...")
        loaded_params = {}
        for name, param in trainer2.get_model().named_parameters():
            loaded_params[name] = param.data.clone()
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¯”è¼ƒ
        params_match = True
        for name in initial_params:
            if not torch.equal(initial_params[name], loaded_params[name]):
                params_match = False
                print(f"Parameter mismatch: {name}")
                break
        
        if params_match:
            print("âœ… Model parameters loaded correctly!")
        else:
            print("âŒ Model parameters do not match!")
            return False
        
        # Step 6: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ãƒ†ã‚¹ãƒˆ
        print("\n6. Testing model cleanup...")
        # ã„ãã¤ã‹ã®ã‚¨ãƒãƒƒã‚¯ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        for epoch in range(1, 6):
            trainer1.save_model(epoch=epoch, loss=0.4-epoch*0.05)
        
        files_before_cleanup = len(os.listdir(models_dir))
        print(f"Files before cleanup: {files_before_cleanup}")
        
        # å¤ã„ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ï¼ˆæœ€æ–°3å€‹ã‚’ä¿æŒï¼‰
        trainer1.cleanup_old_models(keep_last_n=3)
        
        files_after_cleanup = len(os.listdir(models_dir))
        print(f"Files after cleanup: {files_after_cleanup}")
        
        # Step 7: ã‚³ãƒ³ãƒ•ã‚£ã‚°ãƒãƒƒã‚·ãƒ¥ã®ãƒ†ã‚¹ãƒˆ
        print("\n7. Testing config hash consistency...")
        hash1 = trainer1._get_config_hash()
        hash2 = trainer2._get_config_hash()
        
        if hash1 == hash2:
            print(f"âœ… Config hashes match: {hash1}")
        else:
            print(f"âŒ Config hash mismatch: {hash1} vs {hash2}")
            return False
        
        print("\nâœ… All tests passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if os.path.exists("./test_saved_models"):
            shutil.rmtree("./test_saved_models")
        if os.path.exists("./test_configs"):
            shutil.rmtree("./test_configs")

if __name__ == "__main__":
    success = test_model_saving_loading()
    if success:
        print("\nğŸ‰ Model persistence functionality is working correctly!")
    else:
        print("\nğŸ’¥ Model persistence functionality has issues!")
        exit(1)