{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_mode = True\n",
    "viz_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. GPU cannot be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU can be used.\")\n",
    "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU device:\", torch.cuda.current_device())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"CUDA is not available. GPU cannot be used.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter  # tensorboardXの代替\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "# Remove warning\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from scipy.sparse import SparseEfficiencyWarning\n",
    "warnings.simplefilter('ignore', SparseEfficiencyWarning)\n",
    "\n",
    "from config import *\n",
    "from utils.graph_utils import *\n",
    "from utils.exact_solution import SolveExactSolution\n",
    "from utils.flow import Flow\n",
    "from utils.data_maker import DataMaker\n",
    "#from utils.uelb_reader import GoogleTSPReader\n",
    "from utils.plot_utils import *\n",
    "from models.gcn_model import ResidualGatedGCNModel\n",
    "from utils.model_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/18/jb6sg5tn0wd0md220_4vpttw0000gn/T/ipykernel_81163/3855748638.py:6: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('png')\n"
     ]
    }
   ],
   "source": [
    "if notebook_mode == True:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %matplotlib inline\n",
    "    from IPython.display import set_matplotlib_formats\n",
    "    set_matplotlib_formats('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configs/default.json:\n",
      "{'expt_name': 'deafult', 'gpu_id': '0', 'graph_filepath': './data/graph.gml', 'edge_numbering_filepath': './data/edge_numbering_file.csv', 'train_filepath': './data/gragh.gml', 'val_filepath': './data/tsp10_val_concorde.txt', 'test_filepath': './data/tsp10_test_concorde.txt', 'solver_type': 'pulp', 'graph_model': 'nsfnet', 'num_data': 50, 'num_nodes': 14, 'num_neighbors': 5, 'num_commodities': 10, 'sample_size': 5, 'capacity_lower': 500, 'capacity_higher': 1000, 'demand_lower': 1, 'demand_higher': 500, 'node_dim': 10, 'voc_nodes_in': 2, 'voc_nodes_out': 2, 'voc_edges_in': 3, 'voc_edges_out': 2, 'beam_size': 10, 'hidden_dim': 50, 'num_layers': 3, 'mlp_layers': 2, 'aggregation': 'mean', 'max_epochs': 10, 'val_every': 5, 'test_every': 10, 'batch_size': 20, 'batches_per_epoch': 500, 'accumulation_steps': 1, 'learning_rate': 0.001, 'decay_rate': 1.01}\n"
     ]
    }
   ],
   "source": [
    "config_path = \"configs/default.json\"\n",
    "\n",
    "config = get_config(config_path)\n",
    "print(\"Loaded {}:\\n{}\".format(config_path, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure GPU options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config.gpu_id) \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available, using GPU ID {}\".format(config.gpu_id))\n",
    "    dtypeFloat = torch.cuda.FloatTensor\n",
    "    dtypeLong = torch.cuda.LongTensor\n",
    "    torch.cuda.manual_seed(1)\n",
    "else:\n",
    "    print(\"CUDA not available\")\n",
    "    dtypeFloat = torch.float\n",
    "    dtypeLong = torch.long\n",
    "    torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make graph dataset\n",
    "gragh.gmlとedge_numbering_file.csvの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  data was created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(50513) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50553) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50554) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50556) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50600) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50602) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50603) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50604) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50606) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50608) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50609) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50610) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  data was created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(50611) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50654) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50655) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50656) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50657) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50659) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50662) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50663) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50665) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50666) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50668) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20  data was created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(50669) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50671) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50708) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50709) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50712) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50716) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50717) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50718) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50719) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30  data was created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(50720) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50723) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50726) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50727) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50729) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50731) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50766) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50773) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50775) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50776) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50777) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40  data was created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(50781) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50782) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50783) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50784) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50787) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50788) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50822) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50827) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50828) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50829) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50830) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "num_data = config.num_data\n",
    "solver_type = config.solver_type\n",
    "Maker = DataMaker(config)\n",
    "exact_file_name =\"./data/exact_solution.csv\"\n",
    "infinit_loop_count = 0\n",
    "incorrect_value_count = 0\n",
    "\n",
    "for data in range(num_data):\n",
    "    if data % 10 == 0:\n",
    "        print(data, \" data was created.\")\n",
    "    # ディレクトリ番号の定義\n",
    "    file_number = data - (data % 10)\n",
    "    \n",
    "    # ディレクトリの作成\n",
    "    graph_file_directory = \"./data/graph_file/{}\".format(file_number)\n",
    "    if not os.path.exists(graph_file_directory):\n",
    "        os.makedirs(graph_file_directory)\n",
    "    commodity_file_directory = \"./data/commodity_file/{}\".format(file_number)\n",
    "    if not os.path.exists(commodity_file_directory):\n",
    "        os.makedirs(commodity_file_directory)\n",
    "    edge_file_directory = \"./data/edge_file/{}\".format(file_number)\n",
    "    if not os.path.exists(edge_file_directory):\n",
    "        os.makedirs(edge_file_directory)\n",
    "    node_flow_file_directory = \"./data/node_flow_file/{}\".format(file_number)\n",
    "    if not os.path.exists(node_flow_file_directory):\n",
    "        os.makedirs(node_flow_file_directory)\n",
    "    edge_flow_file_directory = \"./data/edge_flow_file/{}\".format(file_number)\n",
    "    if not os.path.exists(edge_flow_file_directory):\n",
    "        os.makedirs(edge_flow_file_directory)\n",
    "\n",
    "    # ファイル名の定義\n",
    "    graph_file_name = \"./data/graph_file/{file_number}/graph_{data}.gml\".format(file_number=file_number, data=data)\n",
    "    comodity_file_name = \"./data/commodity_file/{file_number}/commodity_data_{data}.csv\".format(file_number=file_number, data=data)\n",
    "    edge_file_name = \"./data/edge_file/{file_number}/edge_numbering_{data}.csv\".format(file_number=file_number, data=data)\n",
    "    node_flow_file_name = \"./data/node_flow_file/{file_number}/node_flow_{data}.csv\".format(file_number=file_number, data=data)\n",
    "    edge_flow_file_name = \"./data/edge_flow_file/{file_number}/edge_flow_{data}.csv\".format(file_number=file_number, data=data)\n",
    "\n",
    "    # 作成したdataが適切で無い場合のやり直し\n",
    "    while True:\n",
    "    # グラフ作成\n",
    "        G = Maker.create_graph()\n",
    "        \n",
    "        # 品種作成\n",
    "        commodity_list = Maker.generate_commodity()\n",
    "        \n",
    "        # グラフの保存\n",
    "        nx.write_gml(G, graph_file_name)\n",
    "\n",
    "        # 品種の保存\n",
    "        with open((comodity_file_name), 'w') as f:\n",
    "            writer = csv.writer(f, lineterminator='\\n')\n",
    "            writer.writerows(commodity_list)\n",
    "\n",
    "        # 厳密解の計算\n",
    "        E = SolveExactSolution(solver_type, comodity_file_name, graph_file_name)\n",
    "        flow_var_kakai, edge_list, objective_value, elapsed_time = E.solve_exact_solution_to_env()\n",
    "        node_flow_matrix, edge_flow_matrix, infinit_loop = E.generate_flow_matrices(flow_var_kakai)\n",
    "        \n",
    "        # 厳密解が1以上、または厳密解のフローが正しく導けなかった場合のやり直し\n",
    "        if infinit_loop:\n",
    "            infinit_loop_count += 1\n",
    "        elif objective_value >= 1.0:\n",
    "            incorrect_value_count += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # エッジの保存\n",
    "    with open(edge_file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for item in edge_list:\n",
    "            writer.writerow([item[0], item[1][0], item[1][1]])\n",
    "    \n",
    "    # 厳密解の保存\n",
    "    with open(exact_file_name, 'a', newline='') as f:\n",
    "        out = csv.writer(f)\n",
    "        out.writerow([objective_value,elapsed_time]) \n",
    "\n",
    "    # 厳密解のノードのフローの保存\n",
    "    with open(node_flow_file_name, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in node_flow_matrix:\n",
    "            writer.writerow(row)\n",
    "    # 厳密解のエッジのフローの保存\n",
    "    with open(edge_flow_file_name, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in edge_flow_matrix:\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/gragh.gml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m      5\u001b[0m train_filepath \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtrain_filepath\n\u001b[0;32m----> 6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mGoogleTSPReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of batches of size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_size, dataset\u001b[38;5;241m.\u001b[39mmax_iter))\n\u001b[1;32m      9\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/Desktop/Research/graph-convnet-uelb/utils/uelb_reader.py:41\u001b[0m, in \u001b[0;36mGoogleTSPReader.__init__\u001b[0;34m(self, num_nodes, num_neighbors, batch_size, filepath)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath \u001b[38;5;241m=\u001b[39m filepath\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiledata \u001b[38;5;241m=\u001b[39m shuffle(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreadlines())  \u001b[38;5;66;03m# Always shuffle upon reading data\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiledata) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/gragh.gml'"
     ]
    }
   ],
   "source": [
    "if notebook_mode:\n",
    "    num_nodes = config.num_nodes\n",
    "    num_neighbors = config.num_neighbors\n",
    "    batch_size = config.batch_size\n",
    "    train_filepath = config.train_filepath\n",
    "    #　DataMakerを繰り返し呼び出しバッチごとにtensorを生成する\n",
    "    dataset = GoogleTSPReader(num_nodes, num_neighbors, batch_size, train_filepath)\n",
    "    print(\"Number of batches of size {}: {}\".format(batch_size, dataset.max_iter))\n",
    "\n",
    "    t = time.time()\n",
    "    batch = next(iter(dataset))  # Generate a batch of TSPs\n",
    "    print(\"Batch generation took: {:.3f} sec\".format(time.time() - t))\n",
    "    print(\"edges:\", batch.edges.shape)\n",
    "    print(\"edges_values:\", batch.edges_values.shape)\n",
    "    print(\"edges_targets:\", batch.edges_target.shape)\n",
    "    print(\"nodes:\", batch.nodes.shape)\n",
    "    print(\"nodes_target:\", batch.nodes_target.shape)\n",
    "    print(\"nodes_commodities:\", batch.nodes_coord.shape)\n",
    "    print(\"tour_nodes:\", batch.tour_nodes.shape)\n",
    "    print(\"tour_len:\", batch.tour_len.shape)\n",
    "\n",
    "    idx = 0\n",
    "    f = plt.figure(figsize=(5, 5))\n",
    "    a = f.add_subplot(111)\n",
    "    plot_tsp(a, batch.nodes_coord[idx], batch.edges[idx], batch.edges_values[idx], batch.edges_target[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcn-tsp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
